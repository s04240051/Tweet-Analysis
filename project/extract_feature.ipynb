{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hzhu/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/hzhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/hzhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hzhu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/hzhu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('stopwords', 'punkt', 'wordnet')\n",
    "import re \n",
    "from textblob import TextBlob\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textstat.textstat import textstatistics\n",
    "import textstat\n",
    "from ANEW_util import analyze_line\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(path1):\n",
    "    out = []\n",
    "    with open(path1,\"r\", encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        \n",
    "        for line in reader:\n",
    "            out.append(line)\n",
    "    df = pd.DataFrame(out, columns=[\"time\", \"text\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './emma/name_text/POTUS_President Biden_1349149096909668363.csv'\n",
    "df = open_file(path1)\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_tweet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize_sentiment_textblob(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob. \n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    '''\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    '''\n",
    "    return float(analysis.sentiment.polarity)\n",
    "\n",
    "\n",
    "def vader_index(tweets):\n",
    "    sub_dict = defaultdict(list)\n",
    "    keys = ['neg', 'neu', 'pos', 'compound']\n",
    "    for text in tweets.values:\n",
    "        score = sid.polarity_scores(text)\n",
    "        for key in keys:\n",
    "            sub_dict[key].append(score[key]) \n",
    "        if score['compound'] >= 0.05:\n",
    "            cl = 1\n",
    "        elif 0.05<score['compound']<0.05:\n",
    "            cl = 0\n",
    "        else:\n",
    "            cl = -1\n",
    "        sub_dict[\"sentiment_class_vader\"].append(cl)\n",
    "    return pd.DataFrame(sub_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, vader_index(df['text'])], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readability \n",
    "(from https://www.geeksforgeeks.org/readability-index-pythonnlp/)\n",
    "### The Dale Chall Formula:\n",
    "Raw score = 0.1579*(PDW) + 0.0496*(ASL) + 3.6365  \n",
    "Here,  \n",
    "PDW = Percentage of difficult words not on the Dale–Chall word list.\n",
    "ASL = Average sentence length\n",
    "### The Gunning fog Formula\n",
    "Grade level= 0.4 * ( (average sentence length) + (percentage of Hard Words) )  \n",
    "Here, Hard Words = words with more than two syllables.\n",
    "### Smog Formula\n",
    "SMOG grading = 3 + √(polysyllable count).  \n",
    "Here, polysyllable count = number of words of more than two syllables in a   \n",
    "sample of 30 sentences.\n",
    "### Flesch Formula\n",
    "Reading Ease score = 206.835 - (1.015 × ASL) - (84.6 × ASW)  \n",
    "Here,  \n",
    "ASL = average sentence length (number of words divided by number of sentences)  \n",
    "ASW = average word length in syllables (number of syllables divided by number of words)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the text into sentences, using\n",
    "# Spacy's sentence segmentation which can\n",
    "\n",
    "def break_sentences(text):\n",
    "\tnlp = spacy.load('en_core_web_sm')\n",
    "\tdoc = nlp(text)\n",
    "\treturn list(doc.sents)\n",
    "\n",
    "# Returns Number of Words in the text\n",
    "def word_count(text):\n",
    "\tsentences = break_sentences(text)\n",
    "\twords = 0\n",
    "\tfor sentence in sentences:\n",
    "\t\twords += len([token for token in sentence])\n",
    "\treturn words\n",
    "\n",
    "# Returns the number of sentences in the text\n",
    "def sentence_count(text):\n",
    "\tsentences = break_sentences(text)\n",
    "\treturn len(sentences)\n",
    "\n",
    "# Returns average sentence length\n",
    "def avg_sentence_length(text):\n",
    "\twords = word_count(text)\n",
    "\tsentences = sentence_count(text)\n",
    "\taverage_sentence_length = float(words / sentences)\n",
    "\treturn average_sentence_length\n",
    "\n",
    "# Textstat is a python package, to calculate statistics from\n",
    "# text to determine readability,\n",
    "# complexity and grade level of a particular corpus.\n",
    "\n",
    "def syllables_count(word):\n",
    "\treturn textstatistics().syllable_count(word)\n",
    "\n",
    "# Returns the average number of syllables per\n",
    "# word in the text\n",
    "def avg_syllables_per_word(text):\n",
    "\tsyllable = syllables_count(text)\n",
    "\twords = word_count(text)\n",
    "\tASPW = float(syllable) / float(words)\n",
    "\treturn legacy_round(ASPW, 1)\n",
    "\n",
    "# Return total Difficult Words in a text\n",
    "def difficult_words(text):\n",
    "\t\n",
    "\tnlp = spacy.load('en_core_web_sm')\n",
    "\tdoc = nlp(text)\n",
    "\t# Find all words in the text\n",
    "\twords = []\n",
    "\tsentences = break_sentences(text)\n",
    "\tfor sentence in sentences:\n",
    "\t\twords += [str(token) for token in sentence]\n",
    "\n",
    "\t# difficult words are those with syllables >= 2\n",
    "\t# easy_word_set is provide by Textstat as\n",
    "\t# a list of common words\n",
    "\tdiff_words_set = set()\n",
    "\t\n",
    "\tfor word in words:\n",
    "\t\tsyllable_count = syllables_count(word)\n",
    "\t\tif word not in nlp.Defaults.stop_words and syllable_count >= 2:\n",
    "\t\t\tdiff_words_set.add(word)\n",
    "\n",
    "\treturn len(diff_words_set)\n",
    "\n",
    "# A word is polysyllablic if it has more than 3 syllables\n",
    "# this functions returns the number of all such words\n",
    "# present in the text\n",
    "def poly_syllable_count(text):\n",
    "\tcount = 0\n",
    "\twords = []\n",
    "\tsentences = break_sentences(text)\n",
    "\tfor sentence in sentences:\n",
    "\t\twords += [token for token in sentence]\n",
    "\t\n",
    "\n",
    "\tfor word in words:\n",
    "\t\tsyllable_count = syllables_count(word)\n",
    "\t\tif syllable_count >= 3:\n",
    "\t\t\tcount += 1\n",
    "\treturn count\n",
    "\n",
    "\n",
    "def flesch_reading_ease(text):\n",
    "\t\"\"\"\n",
    "\t\tImplements Flesch Formula:\n",
    "\t\tReading Ease score = 206.835 - (1.015 × ASL) - (84.6 × ASW)\n",
    "\t\tHere,\n",
    "\t\tASL = average sentence length (number of words\n",
    "\t\t\t\tdivided by number of sentences)\n",
    "\t\tASW = average word length in syllables (number of syllables\n",
    "\t\t\t\tdivided by number of words)\n",
    "\t\"\"\"\n",
    "\tFRE = 206.835 - float(1.015 * avg_sentence_length(text)) -\\\n",
    "\t\tfloat(84.6 * avg_syllables_per_word(text))\n",
    "\treturn legacy_round(FRE, 2)\n",
    "\n",
    "\n",
    "def gunning_fog(text):\n",
    "\tper_diff_words = (difficult_words(text) / word_count(text) * 100) + 5\n",
    "\tgrade = 0.4 * (avg_sentence_length(text) + per_diff_words)\n",
    "\treturn grade\n",
    "\n",
    "\n",
    "def smog_index(text):\n",
    "\t\"\"\"\n",
    "\t\tImplements SMOG Formula / Grading\n",
    "\t\tSMOG grading = 3 + ?polysyllable count.\n",
    "\t\tHere,\n",
    "\t\tpolysyllable count = number of words of more\n",
    "\t\tthan two syllables in a sample of 30 sentences.\n",
    "\t\"\"\"\n",
    "\n",
    "\tif sentence_count(text) >= 3:\n",
    "\t\tpoly_syllab = poly_syllable_count(text)\n",
    "\t\tSMOG = (1.043 * (30*(poly_syllab / sentence_count(text)))**0.5) \\\n",
    "\t\t\t\t+ 3.1291\n",
    "\t\treturn legacy_round(SMOG, 1)\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(text):\n",
    "\t\"\"\"\n",
    "\t\tImplements Dale Challe Formula:\n",
    "\t\tRaw score = 0.1579*(PDW) + 0.0496*(ASL) + 3.6365\n",
    "\t\tHere,\n",
    "\t\t\tPDW = Percentage of difficult words.\n",
    "\t\t\tASL = Average sentence length\n",
    "\t\"\"\"\n",
    "\twords = word_count(text)\n",
    "\t# Number of words not termed as difficult words\n",
    "\tcount = word_count - difficult_words(text)\n",
    "\tif words > 0:\n",
    "\n",
    "\t\t# Percentage of words not on difficult word list\n",
    "\n",
    "\t\tper = float(count) / float(words) * 100\n",
    "\t\n",
    "\t# diff_words stores percentage of difficult words\n",
    "\tdiff_words = 100 - per\n",
    "\n",
    "\traw_score = (0.1579 * diff_words) + \\\n",
    "\t\t\t\t(0.0496 * avg_sentence_length(text))\n",
    "\t\n",
    "\t# If Percentage of Difficult Words is greater than 5 %, then;\n",
    "\t# Adjusted Score = Raw Score + 3.6365,\n",
    "\t# otherwise Adjusted Score = Raw Score\n",
    "\n",
    "\tif diff_words > 5:\t\n",
    "\n",
    "\t\traw_score += 3.6365\n",
    "\t\t\n",
    "\treturn legacy_round(raw_score, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_info(df):\n",
    "    df[\"flesch_reading\"] = df[\"text\"].apply(textstat.flesch_reading_ease)\n",
    "    df[\"smog_index\"] = df[\"text\"].apply(textstat.smog_index)\n",
    "    df[\"flesch_kincaid\"] = df[\"text\"].apply(textstat.flesch_kincaid_grade) # like others, can also get from textacy\n",
    "    df[\"coleman_liau\"] = df[\"text\"].apply(textstat.coleman_liau_index)\n",
    "    df[\"automated_readability_index\"] = df[\"text\"].apply(textstat.automated_readability_index)\n",
    "    df[\"dale_chall_readability\"] = df[\"text\"].apply(textstat.dale_chall_readability_score)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small scale test\n",
    "df = pd.concat([df, analyze_line(df['text'].values[:5], mode='mean')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment_class_vader</th>\n",
       "      <th>flesch_reading</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>flesch_kincaid</th>\n",
       "      <th>...</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "      <th>Average VAD</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th># Words Found</th>\n",
       "      <th>Found Words</th>\n",
       "      <th>All Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-31T23:41:20.000Z</td>\n",
       "      <td>In 2022 we took on some of our nation s greate...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>1</td>\n",
       "      <td>74.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>11.10</td>\n",
       "      <td>5.692500</td>\n",
       "      <td>4.825000</td>\n",
       "      <td>5.247500</td>\n",
       "      <td>5.255000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>[take, nation, challenge, deliver]</td>\n",
       "      <td>[take, nation, greatest, challenge, deliver]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-31T19:30:14.000Z</td>\n",
       "      <td>Jill and I join Catholics and others around th...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>1</td>\n",
       "      <td>37.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>...</td>\n",
       "      <td>24.7</td>\n",
       "      <td>12.12</td>\n",
       "      <td>5.534706</td>\n",
       "      <td>3.774118</td>\n",
       "      <td>5.247647</td>\n",
       "      <td>4.852157</td>\n",
       "      <td>neutral</td>\n",
       "      <td>17 out of 24</td>\n",
       "      <td>[join, catholic, world, mourn, pope, pope, rem...</td>\n",
       "      <td>[jill, join, catholic, others, around, world, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-31T17:42:18.000Z</td>\n",
       "      <td>Barbara Walters has always been an example of ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>1</td>\n",
       "      <td>25.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>...</td>\n",
       "      <td>24.8</td>\n",
       "      <td>11.83</td>\n",
       "      <td>6.233571</td>\n",
       "      <td>4.408571</td>\n",
       "      <td>5.782857</td>\n",
       "      <td>5.475000</td>\n",
       "      <td>positive</td>\n",
       "      <td>14 out of 22</td>\n",
       "      <td>[example, bravery, truth, break, barrier, driv...</td>\n",
       "      <td>[barbara, walter, always, example, bravery, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-31T17:00:00.000Z</td>\n",
       "      <td>Just 12 hours until many of the cost saving pr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>60.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.40</td>\n",
       "      <td>5.312222</td>\n",
       "      <td>4.362222</td>\n",
       "      <td>5.408889</td>\n",
       "      <td>5.027778</td>\n",
       "      <td>neutral</td>\n",
       "      <td>9 out of 10</td>\n",
       "      <td>[hour, cost, save, provision, inflation, reduc...</td>\n",
       "      <td>[hour, many, cost, save, provision, inflation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-30T22:45:00.000Z</td>\n",
       "      <td>Jill and I send our deepest and heartfelt cond...</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.1717</td>\n",
       "      <td>-1</td>\n",
       "      <td>53.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>17.2</td>\n",
       "      <td>9.97</td>\n",
       "      <td>5.634167</td>\n",
       "      <td>4.213333</td>\n",
       "      <td>5.575000</td>\n",
       "      <td>5.140833</td>\n",
       "      <td>neutral</td>\n",
       "      <td>12 out of 17</td>\n",
       "      <td>[send, heartfelt, prime, minister, loss, mothe...</td>\n",
       "      <td>[jill, send, deepest, heartfelt, condolence, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time   \n",
       "0  2022-12-31T23:41:20.000Z  \\\n",
       "1  2022-12-31T19:30:14.000Z   \n",
       "2  2022-12-31T17:42:18.000Z   \n",
       "3  2022-12-31T17:00:00.000Z   \n",
       "4  2022-12-30T22:45:00.000Z   \n",
       "\n",
       "                                                text    neg    neu    pos   \n",
       "0  In 2022 we took on some of our nation s greate...  0.000  0.667  0.333  \\\n",
       "1  Jill and I join Catholics and others around th...  0.052  0.746  0.202   \n",
       "2  Barbara Walters has always been an example of ...  0.000  0.758  0.242   \n",
       "3  Just 12 hours until many of the cost saving pr...  0.000  1.000  0.000   \n",
       "4  Jill and I send our deepest and heartfelt cond...  0.134  0.776  0.090   \n",
       "\n",
       "   compound  sentiment_class_vader  flesch_reading  smog_index   \n",
       "0    0.6705                      1           74.19         0.0  \\\n",
       "1    0.8176                      1           37.65         0.0   \n",
       "2    0.9153                      1           25.80         0.0   \n",
       "3    0.0000                     -1           60.65         0.0   \n",
       "4   -0.1717                     -1           53.89         0.0   \n",
       "\n",
       "   flesch_kincaid  ...  automated_readability_index  dale_chall_readability   \n",
       "0             6.4  ...                          5.8                   11.10  \\\n",
       "1            20.4  ...                         24.7                   12.12   \n",
       "2            20.8  ...                         24.8                   11.83   \n",
       "3             9.5  ...                          9.9                   10.40   \n",
       "4            14.2  ...                         17.2                    9.97   \n",
       "\n",
       "    Valence   Arousal  Dominance  Average VAD  Sentiment Label # Words Found   \n",
       "0  5.692500  4.825000   5.247500     5.255000          neutral    4 out of 5  \\\n",
       "1  5.534706  3.774118   5.247647     4.852157          neutral  17 out of 24   \n",
       "2  6.233571  4.408571   5.782857     5.475000         positive  14 out of 22   \n",
       "3  5.312222  4.362222   5.408889     5.027778          neutral   9 out of 10   \n",
       "4  5.634167  4.213333   5.575000     5.140833          neutral  12 out of 17   \n",
       "\n",
       "                                         Found Words   \n",
       "0                 [take, nation, challenge, deliver]  \\\n",
       "1  [join, catholic, world, mourn, pope, pope, rem...   \n",
       "2  [example, bravery, truth, break, barrier, driv...   \n",
       "3  [hour, cost, save, provision, inflation, reduc...   \n",
       "4  [send, heartfelt, prime, minister, loss, mothe...   \n",
       "\n",
       "                                           All Words  \n",
       "0       [take, nation, greatest, challenge, deliver]  \n",
       "1  [jill, join, catholic, others, around, world, ...  \n",
       "2  [barbara, walter, always, example, bravery, tr...  \n",
       "3  [hour, many, cost, save, provision, inflation,...  \n",
       "4  [jill, send, deepest, heartfelt, condolence, p...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/ivi/ilps/personal/hzhu/dataset/emma/name_text/'\n",
    "out_path = '/ivi/ilps/personal/hzhu/dataset/emma/extracted_features'\n",
    "candidators = ['Barack', 'Mitt', 'Hillary', 'Donald', 'Joe', 'POTUS']\n",
    "result_set = []\n",
    "for name in os.listdir(data_folder):\n",
    "    sub_result = sum([name.startswith(item) for item in candidators])\n",
    "    if sub_result>0:\n",
    "        result_set.append(name)\n",
    "\n",
    "def data_pipeline(name_list, main_path, save_path, mode):\n",
    "    for name in tqdm(name_list):\n",
    "        path = os.path.join(main_path, name)\n",
    "        df = open_file(path)\n",
    "        df['text'] = df['text'].apply(clean_tweet)\n",
    "        df = pd.concat([df, vader_index(df['text'])], axis=1)\n",
    "        df = read_info(df)\n",
    "        df = pd.concat([df, analyze_line(df['text'].values[:5], mode=mode)], axis=1)\n",
    "\n",
    "        out_path = os.path.join(save_path, name)\n",
    "        df.to_csv(out_path, index=False)\n",
    "data_pipeline(result_set, data_folder, out_path, mode='mean')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMConv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
